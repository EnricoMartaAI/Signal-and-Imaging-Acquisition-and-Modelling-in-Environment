{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9661391,"sourceType":"datasetVersion","datasetId":5902742}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"collapsed_sections":["qZoK2jg-eQ1z"]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"qZoK2jg-eQ1z"}},{"cell_type":"code","source":["pip install -U albumentations"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:09.051400Z","iopub.execute_input":"2024-10-31T17:23:09.052357Z","iopub.status.idle":"2024-10-31T17:23:23.789734Z","shell.execute_reply.started":"2024-10-31T17:23:09.052303Z","shell.execute_reply":"2024-10-31T17:23:23.788039Z"},"trusted":true,"id":"Qs8oqUWneQ11","outputId":"3647d6ef-601c-426d-b4dd-2522671a973f"},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.17)\nCollecting albumentations\n  Downloading albumentations-1.4.20-py3-none-any.whl.metadata (32 kB)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.14.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (2.9.2)\nCollecting albucore==0.0.19 (from albumentations)\n  Downloading albucore-0.0.19-py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.10.0.84)\nCollecting stringzilla>=3.10.4 (from albucore==0.0.19->albumentations)\n  Downloading stringzilla-3.10.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\nDownloading albumentations-1.4.20-py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.8/225.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading albucore-0.0.19-py3-none-any.whl (11 kB)\nDownloading stringzilla-3.10.7-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (291 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.4/291.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: stringzilla, albucore, albumentations\n  Attempting uninstall: albucore\n    Found existing installation: albucore 0.0.17\n    Uninstalling albucore-0.0.17:\n      Successfully uninstalled albucore-0.0.17\n  Attempting uninstall: albumentations\n    Found existing installation: albumentations 1.4.17\n    Uninstalling albumentations-1.4.17:\n      Successfully uninstalled albumentations-1.4.17\nSuccessfully installed albucore-0.0.19 albumentations-1.4.20 stringzilla-3.10.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":["import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchinfo import summary\n","import cv2\n","import itertools\n","import random"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:23.791896Z","iopub.execute_input":"2024-10-31T17:23:23.792284Z","iopub.status.idle":"2024-10-31T17:23:30.858326Z","shell.execute_reply.started":"2024-10-31T17:23:23.792243Z","shell.execute_reply":"2024-10-31T17:23:30.857071Z"},"trusted":true,"id":"eMpcBaoaeQ12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preparation"],"metadata":{"id":"oXxhhOU-eQ12"}},{"cell_type":"code","source":["## Here is created a list to store the image paths and a list to store the masks\n","# Directories for the original images\n","dataset1_original_images_dir = '/kaggle/input/droneimages/Dataset1/Dataset/original_images'\n","dataset2_original_images_dir = '/kaggle/input/droneimages/Dataset2/Dataset/original_images'\n","\n","# Create a list to store the image paths\n","image_paths = []\n","\n","# Add files from Dataset1\n","for root, dirs, files in os.walk(dataset1_original_images_dir):\n","    for file in files:\n","        if file.endswith(('jpg', 'png')):\n","            image_paths.append(os.path.join(root, file))\n","\n","# Add files from Dataset2\n","for root, dirs, files in os.walk(dataset2_original_images_dir):\n","    for file in files:\n","        if file.endswith(('jpg', 'png')):\n","            image_paths.append(os.path.join(root, file))\n","\n","# Convert the list into a DataFrame\n","df_images = pd.DataFrame(image_paths)\n","\n","# Save the DataFrame to a CSV file\n","df_images.to_csv('/kaggle/working/image_paths.csv', index=False, header=False)\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:30.859665Z","iopub.execute_input":"2024-10-31T17:23:30.860163Z","iopub.status.idle":"2024-10-31T17:23:31.082540Z","shell.execute_reply.started":"2024-10-31T17:23:30.860126Z","shell.execute_reply":"2024-10-31T17:23:31.081340Z"},"trusted":true,"id":"0-tHoC3XeQ12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training set (90%) and validation set (10%)\n","train_data, val_data = train_test_split(df_images, test_size=0.10, random_state=42)\n","\n","# Save these splits into CSV\n","train_data.to_csv('/kaggle/working/train_set.csv', index=False, header=False)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.085318Z","iopub.execute_input":"2024-10-31T17:23:31.085793Z","iopub.status.idle":"2024-10-31T17:23:31.101423Z","shell.execute_reply.started":"2024-10-31T17:23:31.085742Z","shell.execute_reply":"2024-10-31T17:23:31.100165Z"},"trusted":true,"id":"hPx24-96eQ12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"Axf1AwrMeQ12"}},{"cell_type":"code","source":["puzzle_size = 2\n","n_patches = puzzle_size * puzzle_size\n","\n","# List of all permutations for a puzzle_size x puzzle_size puzzle\n","all_permutations = list(itertools.permutations(range(n_patches)))\n","\n","# A map from permutation to label\n","perm_to_label = {perm: idx for idx, perm in enumerate(all_permutations)}\n","\n","n_classes = len(all_permutations)"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.102824Z","iopub.execute_input":"2024-10-31T17:23:31.103622Z","iopub.status.idle":"2024-10-31T17:23:31.112641Z","shell.execute_reply.started":"2024-10-31T17:23:31.103574Z","shell.execute_reply":"2024-10-31T17:23:31.111280Z"},"trusted":true,"id":"ubv1eQ2QeQ13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_permuted_image(image, permutation, puzzle_size=2):\n","    img_width, img_height = image.size\n","    piece_width = img_width // puzzle_size\n","    piece_height = img_height // puzzle_size\n","\n","    # create pieces\n","    pieces = []\n","    for i in range(puzzle_size):\n","        for j in range(puzzle_size):\n","            left = j * piece_width\n","            upper = i * piece_height\n","            right = left + piece_width\n","            lower = upper + piece_height\n","            piece = image.crop((left, upper, right, lower))\n","            pieces.append(piece)\n","\n","    # permutation\n","    permuted_pieces = [pieces[idx] for idx in permutation]\n","\n","    # Reconstruct the permuted image\n","    new_image = Image.new('RGB', (img_width, img_height))\n","    for idx, piece in enumerate(permuted_pieces):\n","        i = idx // puzzle_size\n","        j = idx % puzzle_size\n","        left = j * piece_width\n","        upper = i * piece_height\n","        new_image.paste(piece, (left, upper))\n","\n","    return new_image\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.114089Z","iopub.execute_input":"2024-10-31T17:23:31.114495Z","iopub.status.idle":"2024-10-31T17:23:31.132055Z","shell.execute_reply.started":"2024-10-31T17:23:31.114450Z","shell.execute_reply":"2024-10-31T17:23:31.130382Z"},"trusted":true,"id":"FbOman7OeQ13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class SSLDataset(Dataset):\n","    def __init__(self, csv_file, puzzle_size=2, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.puzzle_size = puzzle_size\n","        self.transform = transform\n","        self.permutations = list(perm_to_label.keys())\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # Load the image\n","        img_path = self.data.iloc[idx, 0]\n","        image = Image.open(img_path).convert('RGB')\n","\n","        # Randomly select a permutation\n","        permutation = random.choice(self.permutations)\n","\n","        # The permuted image\n","        modified_image = create_permuted_image(image, permutation, self.puzzle_size)\n","\n","        if self.transform:\n","            modified_image = self.transform(image=np.array(modified_image))['image']\n","\n","\n","        # idx of the this permutation\n","        label = perm_to_label[permutation]\n","\n","        return modified_image, label\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.133455Z","iopub.execute_input":"2024-10-31T17:23:31.133930Z","iopub.status.idle":"2024-10-31T17:23:31.145237Z","shell.execute_reply.started":"2024-10-31T17:23:31.133882Z","shell.execute_reply":"2024-10-31T17:23:31.143970Z"},"trusted":true,"id":"rK0w-h2WeQ13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transformations for training with data augmentation\n","transform_train = A.Compose([\n","    A.Resize(128, 128),  # Resize images to 128x128\n","    A.Normalize(mean=(0.445, 0.443, 0.401),\n","                std=(0.205, 0.200, 0.210)),\n","    ToTensorV2()  # Convert image and its augmentations to a PyTorch tensor\n","])"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.146869Z","iopub.execute_input":"2024-10-31T17:23:31.147272Z","iopub.status.idle":"2024-10-31T17:23:31.164902Z","shell.execute_reply.started":"2024-10-31T17:23:31.147228Z","shell.execute_reply":"2024-10-31T17:23:31.163608Z"},"trusted":true,"id":"pquxyka6eQ13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the dataset\n","train_set = SSLDataset(csv_file='/kaggle/working/train_set.csv', puzzle_size=puzzle_size, transform=transform_train)\n","\n","batch_size = 40\n","\n","# Create the DataLoader\n","trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True,prefetch_factor=4)"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.166430Z","iopub.execute_input":"2024-10-31T17:23:31.166938Z","iopub.status.idle":"2024-10-31T17:23:31.181475Z","shell.execute_reply.started":"2024-10-31T17:23:31.166887Z","shell.execute_reply":"2024-10-31T17:23:31.180387Z"},"trusted":true,"id":"LQyTHBjyeQ13"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# U-Net"],"metadata":{"id":"eGUJNijTeQ13"}},{"cell_type":"code","source":["class DoubleConv(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, mid_channels=None):\n","        super().__init__()\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(mid_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","    def forward(self, x):\n","        return self.double_conv(x)"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.185665Z","iopub.execute_input":"2024-10-31T17:23:31.186095Z","iopub.status.idle":"2024-10-31T17:23:31.194205Z","shell.execute_reply.started":"2024-10-31T17:23:31.186029Z","shell.execute_reply":"2024-10-31T17:23:31.193098Z"},"trusted":true,"id":"9ULwbALpeQ13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Down(nn.Module):\n","    \"\"\"Downscaling with maxpool then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.maxpool_conv = nn.Sequential(\n","            nn.MaxPool2d(2),\n","            DoubleConv(in_channels, out_channels)\n","        )\n","\n","    def forward(self, x):\n","        return self.maxpool_conv(x)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.195402Z","iopub.execute_input":"2024-10-31T17:23:31.195810Z","iopub.status.idle":"2024-10-31T17:23:31.212431Z","shell.execute_reply.started":"2024-10-31T17:23:31.195774Z","shell.execute_reply":"2024-10-31T17:23:31.210969Z"},"trusted":true,"id":"VpZnqqDneQ14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Up(nn.Module):\n","    \"\"\"Upscaling then double conv\"\"\"\n","\n","    def __init__(self, in_channels, out_channels, bilinear=True):\n","        super().__init__()\n","\n","        # if bilinear, use the normal convolutions to reduce the number of channels\n","        if bilinear:\n","            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n","        else:\n","            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n","            self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        x1 = self.up(x1)\n","        # input is CHW\n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","\n","        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n","                        diffY // 2, diffY - diffY // 2])\n","        # if you have padding issues, see\n","        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n","        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n","        x = torch.cat([x2, x1], dim=1)\n","        return self.conv(x)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.213874Z","iopub.execute_input":"2024-10-31T17:23:31.214350Z","iopub.status.idle":"2024-10-31T17:23:31.227614Z","shell.execute_reply.started":"2024-10-31T17:23:31.214302Z","shell.execute_reply":"2024-10-31T17:23:31.226389Z"},"trusted":true,"id":"M_AsNTWseQ14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class OutConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(OutConv, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        return self.conv(x)\n"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.229073Z","iopub.execute_input":"2024-10-31T17:23:31.229530Z","iopub.status.idle":"2024-10-31T17:23:31.246189Z","shell.execute_reply.started":"2024-10-31T17:23:31.229454Z","shell.execute_reply":"2024-10-31T17:23:31.244991Z"},"trusted":true,"id":"PiPWYMejeQ14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNet(nn.Module):\n","    def __init__(self, n_channels,n_classes , bilinear=False):\n","        super(UNet, self).__init__()\n","        self.num_permutations = n_classes\n","        self.n_channels = n_channels\n","        self.bilinear = bilinear\n","\n","        self.inc = (DoubleConv(n_channels, 64))\n","        self.down1 = (Down(64, 128))\n","        self.down2 = (Down(128, 256))\n","        self.down3 = (Down(256, 512))\n","        factor = 2 if bilinear else 1\n","        self.down4 = (Down(512, 1024 // factor))\n","        self.up1 = (Up(1024, 512 // factor, bilinear))\n","        self.up2 = (Up(512, 256 // factor, bilinear))\n","        self.up3 = (Up(256, 128 // factor, bilinear))\n","        self.up4 = (Up(128, 64, bilinear))\n","        self.reduce_spatial1 = nn.Conv2d(64, 64, kernel_size=3, stride=4, padding=1)\n","        self.reduce_spatial2 = nn.Conv2d(64, 64, kernel_size=3, stride=4, padding=1)\n","        self.fc1 = nn.Linear(64 * 8 * 8, n_classes)\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        x = self.reduce_spatial1(x)\n","        x = self.reduce_spatial2(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.247725Z","iopub.execute_input":"2024-10-31T17:23:31.248212Z","iopub.status.idle":"2024-10-31T17:23:31.261685Z","shell.execute_reply.started":"2024-10-31T17:23:31.248161Z","shell.execute_reply":"2024-10-31T17:23:31.260414Z"},"trusted":true,"id":"JRZmG882eQ14"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"urZof6rqeQ14"}},{"cell_type":"code","source":["# Initialize the model\n","model = UNet(n_channels=3,n_classes =n_classes , bilinear=False)\n","\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizer\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# Define the learning rate scheduler\n","scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4)"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.263005Z","iopub.execute_input":"2024-10-31T17:23:31.263382Z","iopub.status.idle":"2024-10-31T17:23:31.706296Z","shell.execute_reply.started":"2024-10-31T17:23:31.263344Z","shell.execute_reply":"2024-10-31T17:23:31.704881Z"},"trusted":true,"id":"jCDuGhdveQ14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if CUDA is available and count the number of GPUs\n","if torch.cuda.is_available():\n","    num_gpus = torch.cuda.device_count()\n","    print(f'Number of GPUs available: {num_gpus}')\n","    if num_gpus < 2:\n","        print(\"There are less than 2 GPUs detected.\")\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')\n","    print('GPU is not available. Using CPU.')"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.707695Z","iopub.execute_input":"2024-10-31T17:23:31.708115Z","iopub.status.idle":"2024-10-31T17:23:31.714576Z","shell.execute_reply.started":"2024-10-31T17:23:31.708075Z","shell.execute_reply":"2024-10-31T17:23:31.713449Z"},"trusted":true,"id":"qBO3wSKieQ14","outputId":"16fe6dd8-a4ce-4e5e-e742-a2947f7c99cb"},"execution_count":null,"outputs":[{"name":"stdout","text":"GPU is not available. Using CPU.\n","output_type":"stream"}]},{"cell_type":"code","source":["## If multiple GPUs are available\n","if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n","    print(\"Using DataParallel for multi-GPU training.\")\n","    model = nn.DataParallel(model, device_ids=[0, 1])\n","\n","## Move the model to device\n","model.to(device)\n","print(f'Model is using device: {device}')\n","\n","if isinstance(model, nn.DataParallel):\n","    print(f'Model is parallelized on devices: {model.device_ids}')"],"metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:23:31.715947Z","iopub.execute_input":"2024-10-31T17:23:31.716395Z","iopub.status.idle":"2024-10-31T17:23:31.738417Z","shell.execute_reply.started":"2024-10-31T17:23:31.716348Z","shell.execute_reply":"2024-10-31T17:23:31.737093Z"},"trusted":true,"id":"REV6rehNeQ14","outputId":"7be06e03-7294-4afb-9570-7a6ff2ebf66e"},"execution_count":null,"outputs":[{"name":"stdout","text":"Model is using device: cpu\n","output_type":"stream"}]},{"cell_type":"code","source":["train_losses = []\n","train_accuracies = []\n","# Training parameters\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}')\n","    print('-' * 10)\n","\n","    # Training Phase\n","    model.train()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    total=0\n","    for inputs, labels in tqdm(trainloader, desc='Training'):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        # Calculate loss\n","        loss = criterion(outputs, labels)\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        running_corrects += torch.sum(preds == labels.data)\n","        total += labels.size(0)\n","\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = running_corrects.double() / total\n","\n","    print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","    train_losses.append(epoch_loss)\n","    train_accuracies.append(epoch_acc)\n","    # Update the scheduler with the validation loss\n","    scheduler.step(epoch_loss)\n","\n","    print()\n","\n","torch.save(model.state_dict(), 'unet_model.pth')\n","print('Model saved!')"],"metadata":{"trusted":true,"id":"fqBg2qOOeQ14"},"execution_count":null,"outputs":[]}]}