{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMJzhiC5tqICf0k0PYkHGSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0w31fL1jn_s","executionInfo":{"status":"ok","timestamp":1727529415818,"user_tz":-120,"elapsed":9032,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"564cc636-e5ed-451b-9a19-d3673b48f9fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","import os\n","from glob import glob\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import zipfile\n","import torch.optim as optim  # Optimization algorithms for training the model\n","import torch.nn.functional as F  # Common loss functions and activation functions\n","import itertools  # Utility functions for generating combinations\n","from torch.optim.lr_scheduler import CosineAnnealingLR  # Learning rate scheduler for training\n","import matplotlib.pyplot as plt  # Plotting library for visualization\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader, Subset\n","import numpy as np\n","from torchsummary import summary\n","from torchvision import transforms\n","\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# Check if GPU (Graphics Processing Unit) is available for training\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","\n","# Define the device to use for training based on GPU availability\n","device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n","\n","# Print the chosen device for training\n","print(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5DV47dy3n1Vo","executionInfo":{"status":"ok","timestamp":1727529415818,"user_tz":-120,"elapsed":4,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"4589281e-0de9-42ce-86a2-3a1532d4bde8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA is available!  Training on GPU ...\n","cuda:0\n"]}]},{"cell_type":"code","source":["# Percorso al file ZIP su Google Drive\n","zip_path = '/content/drive/MyDrive/Colab Notebooks/Enviornment/L3-4/archive.zip'\n","\n","# Directory di destinazione dove verranno estratti i file\n","extract_dir = '/content/images'\n","\n","# Estrazione del file ZIP\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_dir)\n"],"metadata":{"id":"RAOQFezekS6b","executionInfo":{"status":"ok","timestamp":1727529427817,"user_tz":-120,"elapsed":12001,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Directory estratta\n","data_dir = '/content/images/UCMerced_LandUse/Images'\n","\n","# Ottieni le sottocartelle (che rappresentano le classi)\n","class_dirs = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n","\n","# Inizializza una lista per memorizzare i percorsi delle immagini e le rispettive classi\n","image_paths = []\n","numeric_labels = []\n","class_to_idx = {}\n","\n","# Itera attraverso ciascuna cartella (classe) e assegna un indice numerico alle classi\n","for idx, class_dir in enumerate(class_dirs):\n","    class_name = os.path.basename(class_dir)\n","\n","    # Aggiungi la classe al dizionario se non è già presente\n","    class_to_idx[class_name] = idx\n","\n","    # Ottieni tutti i file immagine in formato .tif nella cartella della classe\n","    images = glob(os.path.join(class_dir, '*.tif'))  # Modificato per cercare immagini .tif\n","\n","    # Aggiungi i percorsi delle immagini e la classe numerica (label)\n","    image_paths.extend(images)\n","    numeric_labels.extend([idx] * len(images))  # Assegna la label numerica direttamente\n","\n","# Verifica che le immagini siano state caricate correttamente\n","if image_paths:\n","    print(f'Trovate {len(image_paths)} immagini.')\n","    print('Esempio di percorso immagine:', image_paths[0])\n","    print('Classe associata (numerica):', numeric_labels[0])\n","else:\n","    print('Nessuna immagine trovata. Verifica il percorso o il formato dei file.')\n","\n","print('Mappatura classi:', class_to_idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCRs97LRnGAv","executionInfo":{"status":"ok","timestamp":1727529427818,"user_tz":-120,"elapsed":4,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"af890b9c-32ae-44d0-a47b-ff1a33bf5a8a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Trovate 2100 immagini.\n","Esempio di percorso immagine: /content/images/UCMerced_LandUse/Images/beach/beach71.tif\n","Classe associata (numerica): 0\n","Mappatura classi: {'beach': 0, 'harbor': 1, 'denseresidential': 2, 'forest': 3, 'runway': 4, 'river': 5, 'sparseresidential': 6, 'overpass': 7, 'intersection': 8, 'airplane': 9, 'agricultural': 10, 'mobilehomepark': 11, 'parkinglot': 12, 'freeway': 13, 'storagetanks': 14, 'baseballdiamond': 15, 'chaparral': 16, 'mediumresidential': 17, 'tenniscourt': 18, 'buildings': 19, 'golfcourse': 20}\n"]}]},{"cell_type":"code","source":["# Trasformazioni da applicare alle immagini (es: ridimensionamento, conversione in tensor)\n","transform = transforms.Compose([\n","    transforms.Resize((256, 256)),  # Ridimensiona le immagini\n","    transforms.ToTensor(),  # Converti le immagini in tensor PyTorch\n","])\n","# Dataset personalizzato per PyTorch (uguale a quello precedente)\n","class ImageDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform=None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.labels[idx]\n","\n","        # Carica l'immagine\n","        image = Image.open(img_path).convert('RGB')  # Converte in RGB se necessario\n","\n","        # Applica le trasformazioni (se presenti)\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Funzione per suddividere in modo stratificato per classe\n","def stratified_split(image_paths, labels, train_size=0.7, val_size=0.2, test_size=0.1):\n","    assert np.isclose(train_size + val_size + test_size, 1.0), \"La somma delle frazioni deve essere 1.\"\n","\n","    # Step 1: Suddividi in train e temp (validation + test)\n","    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n","        image_paths, labels, stratify=labels, test_size=(1 - train_size), random_state=42)\n","\n","    # Step 2: Suddividi il temp in validation e test\n","    val_paths, test_paths, val_labels, test_labels = train_test_split(\n","        temp_paths, temp_labels, stratify=temp_labels, test_size=(test_size / (test_size + val_size)), random_state=42)\n","\n","    return train_paths, val_paths, test_paths, train_labels, val_labels, test_labels\n","\n","# Esegui lo split stratificato del dataset\n","train_paths, val_paths, test_paths, train_labels, val_labels, test_labels = stratified_split(\n","    image_paths, numeric_labels, train_size=0.7, val_size=0.2, test_size=0.1)\n","\n","# Crea dataset PyTorch per ogni suddivisione\n","train_dataset = ImageDataset(image_paths=train_paths, labels=train_labels, transform=transform)\n","val_dataset = ImageDataset(image_paths=val_paths, labels=val_labels, transform=transform)\n","test_dataset = ImageDataset(image_paths=test_paths, labels=test_labels, transform=transform)\n","\n","# Crea DataLoader per ogni suddivisione\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# Verifica il caricamento dei dati per il training set\n","train_iter = iter(train_loader)\n","images, labels = next(train_iter)\n","print(f\"Batch di immagini nel training: {images.shape}, Batch di etichette: {labels}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XTKgbFwmnMQo","executionInfo":{"status":"ok","timestamp":1727529428240,"user_tz":-120,"elapsed":425,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"6acebba2-f481-416b-eba5-702665d271bc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch di immagini nel training: torch.Size([32, 3, 256, 256]), Batch di etichette: tensor([15,  4,  0, 12, 18,  9, 13,  0, 15, 14, 18,  0, 20, 10, 13, 14,  1,  7,\n","         9, 14, 16, 14,  7,  9, 19, 15, 19,  3, 17,  0, 13,  5])\n"]}]},{"cell_type":"code","source":["\n","# Define the model architecture (MobileNetV2)\n","# the model is loaded with weights pre-trained on the ImageNet dataset\n","net = torchvision.models.googlenet(weights='IMAGENET1K_V1')  # Load pre-trained weights\n","#print(net)\n","# Adjust the final classification layer\n","# MobileNetV2 was originally designed for classifying 1000 different classes in ImageNet.\n","# Here, the code modifies its classifier to make it suitable for age prediction\n","num_ftrs = net.fc.in_features  # Get the number of input features for the last layer\n","net.fc = nn.Sequential(\n","    nn.Linear(num_ftrs, 512),  # First linear layer with 512 units\n","    nn.GELU(),  # GELU activation function\n","    nn.Linear(512, 32),  # Second linear layer with 32 units\n","    nn.GELU(),  # GELU activation function\n","    nn.Linear(32, 21)   # Output layer with 21 classe\n",")\n","\n","# Move the model to the appropriate device (CPU or GPU)\n","net.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iy-L0Y7CoqJY","executionInfo":{"status":"ok","timestamp":1727529430088,"user_tz":-120,"elapsed":1852,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"e41ca6b4-f599-4941-f3ae-4cdba74d4f25"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:01<00:00, 40.7MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["GoogLeNet(\n","  (conv1): BasicConv2d(\n","    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (conv2): BasicConv2d(\n","    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (conv3): BasicConv2d(\n","    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception3a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception3b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception4a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4c): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4d): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception4e): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (inception5a): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (inception5b): Inception(\n","    (branch1): BasicConv2d(\n","      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (branch2): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch3): Sequential(\n","      (0): BasicConv2d(\n","        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicConv2d(\n","        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (branch4): Sequential(\n","      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","      (1): BasicConv2d(\n","        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","  )\n","  (aux1): None\n","  (aux2): None\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (dropout): Dropout(p=0.2, inplace=False)\n","  (fc): Sequential(\n","    (0): Linear(in_features=1024, out_features=512, bias=True)\n","    (1): GELU(approximate='none')\n","    (2): Linear(in_features=512, out_features=32, bias=True)\n","    (3): GELU(approximate='none')\n","    (4): Linear(in_features=32, out_features=21, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Print model summary\n","summary(net, (3, 256, 256))  # Input shape (channels, height, width)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoFBi6fyo2af","executionInfo":{"status":"ok","timestamp":1727529431692,"user_tz":-120,"elapsed":1606,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"dcc95afb-3ca0-4673-d5e5-c912f6fde739"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           9,408\n","       BatchNorm2d-2         [-1, 64, 128, 128]             128\n","       BasicConv2d-3         [-1, 64, 128, 128]               0\n","         MaxPool2d-4           [-1, 64, 64, 64]               0\n","            Conv2d-5           [-1, 64, 64, 64]           4,096\n","       BatchNorm2d-6           [-1, 64, 64, 64]             128\n","       BasicConv2d-7           [-1, 64, 64, 64]               0\n","            Conv2d-8          [-1, 192, 64, 64]         110,592\n","       BatchNorm2d-9          [-1, 192, 64, 64]             384\n","      BasicConv2d-10          [-1, 192, 64, 64]               0\n","        MaxPool2d-11          [-1, 192, 32, 32]               0\n","           Conv2d-12           [-1, 64, 32, 32]          12,288\n","      BatchNorm2d-13           [-1, 64, 32, 32]             128\n","      BasicConv2d-14           [-1, 64, 32, 32]               0\n","           Conv2d-15           [-1, 96, 32, 32]          18,432\n","      BatchNorm2d-16           [-1, 96, 32, 32]             192\n","      BasicConv2d-17           [-1, 96, 32, 32]               0\n","           Conv2d-18          [-1, 128, 32, 32]         110,592\n","      BatchNorm2d-19          [-1, 128, 32, 32]             256\n","      BasicConv2d-20          [-1, 128, 32, 32]               0\n","           Conv2d-21           [-1, 16, 32, 32]           3,072\n","      BatchNorm2d-22           [-1, 16, 32, 32]              32\n","      BasicConv2d-23           [-1, 16, 32, 32]               0\n","           Conv2d-24           [-1, 32, 32, 32]           4,608\n","      BatchNorm2d-25           [-1, 32, 32, 32]              64\n","      BasicConv2d-26           [-1, 32, 32, 32]               0\n","        MaxPool2d-27          [-1, 192, 32, 32]               0\n","           Conv2d-28           [-1, 32, 32, 32]           6,144\n","      BatchNorm2d-29           [-1, 32, 32, 32]              64\n","      BasicConv2d-30           [-1, 32, 32, 32]               0\n","        Inception-31          [-1, 256, 32, 32]               0\n","           Conv2d-32          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-33          [-1, 128, 32, 32]             256\n","      BasicConv2d-34          [-1, 128, 32, 32]               0\n","           Conv2d-35          [-1, 128, 32, 32]          32,768\n","      BatchNorm2d-36          [-1, 128, 32, 32]             256\n","      BasicConv2d-37          [-1, 128, 32, 32]               0\n","           Conv2d-38          [-1, 192, 32, 32]         221,184\n","      BatchNorm2d-39          [-1, 192, 32, 32]             384\n","      BasicConv2d-40          [-1, 192, 32, 32]               0\n","           Conv2d-41           [-1, 32, 32, 32]           8,192\n","      BatchNorm2d-42           [-1, 32, 32, 32]              64\n","      BasicConv2d-43           [-1, 32, 32, 32]               0\n","           Conv2d-44           [-1, 96, 32, 32]          27,648\n","      BatchNorm2d-45           [-1, 96, 32, 32]             192\n","      BasicConv2d-46           [-1, 96, 32, 32]               0\n","        MaxPool2d-47          [-1, 256, 32, 32]               0\n","           Conv2d-48           [-1, 64, 32, 32]          16,384\n","      BatchNorm2d-49           [-1, 64, 32, 32]             128\n","      BasicConv2d-50           [-1, 64, 32, 32]               0\n","        Inception-51          [-1, 480, 32, 32]               0\n","        MaxPool2d-52          [-1, 480, 16, 16]               0\n","           Conv2d-53          [-1, 192, 16, 16]          92,160\n","      BatchNorm2d-54          [-1, 192, 16, 16]             384\n","      BasicConv2d-55          [-1, 192, 16, 16]               0\n","           Conv2d-56           [-1, 96, 16, 16]          46,080\n","      BatchNorm2d-57           [-1, 96, 16, 16]             192\n","      BasicConv2d-58           [-1, 96, 16, 16]               0\n","           Conv2d-59          [-1, 208, 16, 16]         179,712\n","      BatchNorm2d-60          [-1, 208, 16, 16]             416\n","      BasicConv2d-61          [-1, 208, 16, 16]               0\n","           Conv2d-62           [-1, 16, 16, 16]           7,680\n","      BatchNorm2d-63           [-1, 16, 16, 16]              32\n","      BasicConv2d-64           [-1, 16, 16, 16]               0\n","           Conv2d-65           [-1, 48, 16, 16]           6,912\n","      BatchNorm2d-66           [-1, 48, 16, 16]              96\n","      BasicConv2d-67           [-1, 48, 16, 16]               0\n","        MaxPool2d-68          [-1, 480, 16, 16]               0\n","           Conv2d-69           [-1, 64, 16, 16]          30,720\n","      BatchNorm2d-70           [-1, 64, 16, 16]             128\n","      BasicConv2d-71           [-1, 64, 16, 16]               0\n","        Inception-72          [-1, 512, 16, 16]               0\n","           Conv2d-73          [-1, 160, 16, 16]          81,920\n","      BatchNorm2d-74          [-1, 160, 16, 16]             320\n","      BasicConv2d-75          [-1, 160, 16, 16]               0\n","           Conv2d-76          [-1, 112, 16, 16]          57,344\n","      BatchNorm2d-77          [-1, 112, 16, 16]             224\n","      BasicConv2d-78          [-1, 112, 16, 16]               0\n","           Conv2d-79          [-1, 224, 16, 16]         225,792\n","      BatchNorm2d-80          [-1, 224, 16, 16]             448\n","      BasicConv2d-81          [-1, 224, 16, 16]               0\n","           Conv2d-82           [-1, 24, 16, 16]          12,288\n","      BatchNorm2d-83           [-1, 24, 16, 16]              48\n","      BasicConv2d-84           [-1, 24, 16, 16]               0\n","           Conv2d-85           [-1, 64, 16, 16]          13,824\n","      BatchNorm2d-86           [-1, 64, 16, 16]             128\n","      BasicConv2d-87           [-1, 64, 16, 16]               0\n","        MaxPool2d-88          [-1, 512, 16, 16]               0\n","           Conv2d-89           [-1, 64, 16, 16]          32,768\n","      BatchNorm2d-90           [-1, 64, 16, 16]             128\n","      BasicConv2d-91           [-1, 64, 16, 16]               0\n","        Inception-92          [-1, 512, 16, 16]               0\n","           Conv2d-93          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-94          [-1, 128, 16, 16]             256\n","      BasicConv2d-95          [-1, 128, 16, 16]               0\n","           Conv2d-96          [-1, 128, 16, 16]          65,536\n","      BatchNorm2d-97          [-1, 128, 16, 16]             256\n","      BasicConv2d-98          [-1, 128, 16, 16]               0\n","           Conv2d-99          [-1, 256, 16, 16]         294,912\n","     BatchNorm2d-100          [-1, 256, 16, 16]             512\n","     BasicConv2d-101          [-1, 256, 16, 16]               0\n","          Conv2d-102           [-1, 24, 16, 16]          12,288\n","     BatchNorm2d-103           [-1, 24, 16, 16]              48\n","     BasicConv2d-104           [-1, 24, 16, 16]               0\n","          Conv2d-105           [-1, 64, 16, 16]          13,824\n","     BatchNorm2d-106           [-1, 64, 16, 16]             128\n","     BasicConv2d-107           [-1, 64, 16, 16]               0\n","       MaxPool2d-108          [-1, 512, 16, 16]               0\n","          Conv2d-109           [-1, 64, 16, 16]          32,768\n","     BatchNorm2d-110           [-1, 64, 16, 16]             128\n","     BasicConv2d-111           [-1, 64, 16, 16]               0\n","       Inception-112          [-1, 512, 16, 16]               0\n","          Conv2d-113          [-1, 112, 16, 16]          57,344\n","     BatchNorm2d-114          [-1, 112, 16, 16]             224\n","     BasicConv2d-115          [-1, 112, 16, 16]               0\n","          Conv2d-116          [-1, 144, 16, 16]          73,728\n","     BatchNorm2d-117          [-1, 144, 16, 16]             288\n","     BasicConv2d-118          [-1, 144, 16, 16]               0\n","          Conv2d-119          [-1, 288, 16, 16]         373,248\n","     BatchNorm2d-120          [-1, 288, 16, 16]             576\n","     BasicConv2d-121          [-1, 288, 16, 16]               0\n","          Conv2d-122           [-1, 32, 16, 16]          16,384\n","     BatchNorm2d-123           [-1, 32, 16, 16]              64\n","     BasicConv2d-124           [-1, 32, 16, 16]               0\n","          Conv2d-125           [-1, 64, 16, 16]          18,432\n","     BatchNorm2d-126           [-1, 64, 16, 16]             128\n","     BasicConv2d-127           [-1, 64, 16, 16]               0\n","       MaxPool2d-128          [-1, 512, 16, 16]               0\n","          Conv2d-129           [-1, 64, 16, 16]          32,768\n","     BatchNorm2d-130           [-1, 64, 16, 16]             128\n","     BasicConv2d-131           [-1, 64, 16, 16]               0\n","       Inception-132          [-1, 528, 16, 16]               0\n","          Conv2d-133          [-1, 256, 16, 16]         135,168\n","     BatchNorm2d-134          [-1, 256, 16, 16]             512\n","     BasicConv2d-135          [-1, 256, 16, 16]               0\n","          Conv2d-136          [-1, 160, 16, 16]          84,480\n","     BatchNorm2d-137          [-1, 160, 16, 16]             320\n","     BasicConv2d-138          [-1, 160, 16, 16]               0\n","          Conv2d-139          [-1, 320, 16, 16]         460,800\n","     BatchNorm2d-140          [-1, 320, 16, 16]             640\n","     BasicConv2d-141          [-1, 320, 16, 16]               0\n","          Conv2d-142           [-1, 32, 16, 16]          16,896\n","     BatchNorm2d-143           [-1, 32, 16, 16]              64\n","     BasicConv2d-144           [-1, 32, 16, 16]               0\n","          Conv2d-145          [-1, 128, 16, 16]          36,864\n","     BatchNorm2d-146          [-1, 128, 16, 16]             256\n","     BasicConv2d-147          [-1, 128, 16, 16]               0\n","       MaxPool2d-148          [-1, 528, 16, 16]               0\n","          Conv2d-149          [-1, 128, 16, 16]          67,584\n","     BatchNorm2d-150          [-1, 128, 16, 16]             256\n","     BasicConv2d-151          [-1, 128, 16, 16]               0\n","       Inception-152          [-1, 832, 16, 16]               0\n","       MaxPool2d-153            [-1, 832, 8, 8]               0\n","          Conv2d-154            [-1, 256, 8, 8]         212,992\n","     BatchNorm2d-155            [-1, 256, 8, 8]             512\n","     BasicConv2d-156            [-1, 256, 8, 8]               0\n","          Conv2d-157            [-1, 160, 8, 8]         133,120\n","     BatchNorm2d-158            [-1, 160, 8, 8]             320\n","     BasicConv2d-159            [-1, 160, 8, 8]               0\n","          Conv2d-160            [-1, 320, 8, 8]         460,800\n","     BatchNorm2d-161            [-1, 320, 8, 8]             640\n","     BasicConv2d-162            [-1, 320, 8, 8]               0\n","          Conv2d-163             [-1, 32, 8, 8]          26,624\n","     BatchNorm2d-164             [-1, 32, 8, 8]              64\n","     BasicConv2d-165             [-1, 32, 8, 8]               0\n","          Conv2d-166            [-1, 128, 8, 8]          36,864\n","     BatchNorm2d-167            [-1, 128, 8, 8]             256\n","     BasicConv2d-168            [-1, 128, 8, 8]               0\n","       MaxPool2d-169            [-1, 832, 8, 8]               0\n","          Conv2d-170            [-1, 128, 8, 8]         106,496\n","     BatchNorm2d-171            [-1, 128, 8, 8]             256\n","     BasicConv2d-172            [-1, 128, 8, 8]               0\n","       Inception-173            [-1, 832, 8, 8]               0\n","          Conv2d-174            [-1, 384, 8, 8]         319,488\n","     BatchNorm2d-175            [-1, 384, 8, 8]             768\n","     BasicConv2d-176            [-1, 384, 8, 8]               0\n","          Conv2d-177            [-1, 192, 8, 8]         159,744\n","     BatchNorm2d-178            [-1, 192, 8, 8]             384\n","     BasicConv2d-179            [-1, 192, 8, 8]               0\n","          Conv2d-180            [-1, 384, 8, 8]         663,552\n","     BatchNorm2d-181            [-1, 384, 8, 8]             768\n","     BasicConv2d-182            [-1, 384, 8, 8]               0\n","          Conv2d-183             [-1, 48, 8, 8]          39,936\n","     BatchNorm2d-184             [-1, 48, 8, 8]              96\n","     BasicConv2d-185             [-1, 48, 8, 8]               0\n","          Conv2d-186            [-1, 128, 8, 8]          55,296\n","     BatchNorm2d-187            [-1, 128, 8, 8]             256\n","     BasicConv2d-188            [-1, 128, 8, 8]               0\n","       MaxPool2d-189            [-1, 832, 8, 8]               0\n","          Conv2d-190            [-1, 128, 8, 8]         106,496\n","     BatchNorm2d-191            [-1, 128, 8, 8]             256\n","     BasicConv2d-192            [-1, 128, 8, 8]               0\n","       Inception-193           [-1, 1024, 8, 8]               0\n","AdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n","         Dropout-195                 [-1, 1024]               0\n","          Linear-196                  [-1, 512]         524,800\n","            GELU-197                  [-1, 512]               0\n","          Linear-198                   [-1, 32]          16,416\n","            GELU-199                   [-1, 32]               0\n","          Linear-200                   [-1, 21]             693\n","================================================================\n","Total params: 6,141,813\n","Trainable params: 6,141,813\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 122.91\n","Params size (MB): 23.43\n","Estimated Total Size (MB): 147.09\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# Define training parameters (epochs, loss function, optimizer, and scheduler)\n","epochs = 100  # Number of training epochs\n","criterion = nn.CrossEntropyLoss()  # Cross-Entropy Loss per problemi multiclasse\n","optimizer = optim.Adam(net.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n","scheduler = CosineAnnealingLR(optimizer,\n","                              T_max=len(train_loader) * epochs,  # Maximum number of iterations for scheduler\n","                              eta_min=1e-5)  # Minimum learning rate for scheduler\n"],"metadata":{"id":"PY1d7KHTpBx5","executionInfo":{"status":"ok","timestamp":1727529431692,"user_tz":-120,"elapsed":5,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["'''\n","Training and Validation section.\n","'''\n","\n","# Uncomment if you need to complete the training with pre-saved model\n","#net.load_state_dict(torch.load(\"/kaggle/input/vecchio/net_best.pth\"))\n","\n","# Parameters for the early stopping procedure\n","patience = 6\n","best_val_loss = float('inf')\n","epochs_no_improve = 0\n","\n","# List to evaluate the final model\n","all_preds = []\n","all_labels = []\n","\n","# Training\n","for epoch in range(epochs):\n","    running_loss = []  # List to store training loss for each batch\n","    net.train()  # Set the model to training mode\n","    for i, data in enumerate(train_loader):\n","        # Get inputs and labels from the data loader\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = net(inputs)\n","        # Calculate loss\n","        loss = criterion(outputs.squeeze(), labels)\n","        # Backward pass and parameter update\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        # Print statistics (every 10% of the training data)\n","        running_loss.append(loss.item())\n","        if (i + 1) % (len(train_loader) // 10) == 0:\n","            print('%d, [%d, %d] loss: %.4f\\tlr: %.6f' %\n","                  (epoch + 1, i + 1, len(train_loader), np.mean(running_loss), optimizer.param_groups[-1]['lr']))\n","            running_loss = []\n","\n","    # Validation\n","    running_loss = []  # List to store validation loss for each batch\n","    net.eval()  # Set the model to evaluation mode\n","    correct = 0\n","    total = 0\n","    for i, data in enumerate(val_loader):\n","        # Get inputs and labels from the data loader\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","\n","        # Forward pass with gradient suppression\n","        with torch.no_grad():\n","            outputs = net(inputs)  # Get model predictions without calculating gradients\n","            # Finds the class with the highest probability for each image in the batch.\n","            _, predicted = torch.max(outputs.cpu(), 1)\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","            # Update total number of test images\n","            total += labels.size(0)  # label.size(0) gives the batch size\n","            # Count correct predictions\n","            correct += (predicted == labels.cpu()).sum().item()  # Count true positives\n","\n","        loss = criterion(outputs, labels)  # Calculate Cross Entropy loss\n","        running_loss.append(loss.item())\n","\n","    val_loss = np.mean(running_loss)\n","    print('Validation loss: %.6f' % val_loss)\n","    # Calculate and print accuracy\n","    accuracy = 100 * correct / total\n","    print(f'Validation accuracy: {accuracy:.2f} %')\n","\n","    # Early stopping if no improvement in validation loss\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        epochs_no_improve = 0\n","        torch.save(net.state_dict(), \"net_best.pth\")\n","        print(f\"Epoch {epoch+1}: Validation loss improved to {val_loss:.6f}. Model saved.\")\n","    else:\n","        epochs_no_improve += 1\n","        print(f\"Epoch {epoch+1}: No improvement in validation loss ({val_loss:.6f}). Epochs without improvement: {epochs_no_improve}/{patience}\")\n","\n","    if epochs_no_improve == patience:\n","        print(f\"Early stopping triggered after {epoch+1} epochs. Best validation loss: {best_val_loss:.6f}\")\n","        break\n","\n","print('Finished Training')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-qX4-yxrgPV","executionInfo":{"status":"ok","timestamp":1727529598871,"user_tz":-120,"elapsed":167183,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"cabb1632-46ef-43a3-e5ab-9b7c34380c78"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["1, [4, 46] loss: 2.9957\tlr: 0.001000\n","1, [8, 46] loss: 2.6444\tlr: 0.001000\n","1, [12, 46] loss: 2.0511\tlr: 0.001000\n","1, [16, 46] loss: 2.0611\tlr: 0.001000\n","1, [20, 46] loss: 1.7760\tlr: 0.001000\n","1, [24, 46] loss: 1.4455\tlr: 0.001000\n","1, [28, 46] loss: 1.1726\tlr: 0.001000\n","1, [32, 46] loss: 0.9883\tlr: 0.001000\n","1, [36, 46] loss: 0.9786\tlr: 0.001000\n","1, [40, 46] loss: 0.8704\tlr: 0.001000\n","1, [44, 46] loss: 1.0462\tlr: 0.001000\n","Validation loss: 1.811007\n","Validation accuracy: 50.95 %\n","Epoch 1: Validation loss improved to 1.811007. Model saved.\n","2, [4, 46] loss: 1.0156\tlr: 0.001000\n","2, [8, 46] loss: 0.8417\tlr: 0.001000\n","2, [12, 46] loss: 0.7313\tlr: 0.001000\n","2, [16, 46] loss: 0.7771\tlr: 0.001000\n","2, [20, 46] loss: 0.5888\tlr: 0.000999\n","2, [24, 46] loss: 0.5954\tlr: 0.000999\n","2, [28, 46] loss: 0.6326\tlr: 0.000999\n","2, [32, 46] loss: 0.5848\tlr: 0.000999\n","2, [36, 46] loss: 0.4730\tlr: 0.000999\n","2, [40, 46] loss: 0.5396\tlr: 0.000999\n","2, [44, 46] loss: 0.7695\tlr: 0.000999\n","Validation loss: 0.708045\n","Validation accuracy: 77.62 %\n","Epoch 2: Validation loss improved to 0.708045. Model saved.\n","3, [4, 46] loss: 0.6251\tlr: 0.000999\n","3, [8, 46] loss: 0.3558\tlr: 0.000999\n","3, [12, 46] loss: 0.5483\tlr: 0.000999\n","3, [16, 46] loss: 0.4779\tlr: 0.000999\n","3, [20, 46] loss: 0.4078\tlr: 0.000999\n","3, [24, 46] loss: 0.6085\tlr: 0.000998\n","3, [28, 46] loss: 0.3585\tlr: 0.000998\n","3, [32, 46] loss: 0.3109\tlr: 0.000998\n","3, [36, 46] loss: 0.4011\tlr: 0.000998\n","3, [40, 46] loss: 0.4718\tlr: 0.000998\n","3, [44, 46] loss: 0.5638\tlr: 0.000998\n","Validation loss: 0.450893\n","Validation accuracy: 85.00 %\n","Epoch 3: Validation loss improved to 0.450893. Model saved.\n","4, [4, 46] loss: 0.3756\tlr: 0.000998\n","4, [8, 46] loss: 0.3620\tlr: 0.000998\n","4, [12, 46] loss: 0.1834\tlr: 0.000997\n","4, [16, 46] loss: 0.4495\tlr: 0.000997\n","4, [20, 46] loss: 0.3817\tlr: 0.000997\n","4, [24, 46] loss: 0.5166\tlr: 0.000997\n","4, [28, 46] loss: 0.4590\tlr: 0.000997\n","4, [32, 46] loss: 0.5402\tlr: 0.000997\n","4, [36, 46] loss: 0.3933\tlr: 0.000997\n","4, [40, 46] loss: 0.3458\tlr: 0.000996\n","4, [44, 46] loss: 0.3048\tlr: 0.000996\n","Validation loss: 0.332881\n","Validation accuracy: 92.86 %\n","Epoch 4: Validation loss improved to 0.332881. Model saved.\n","5, [4, 46] loss: 0.2918\tlr: 0.000996\n","5, [8, 46] loss: 0.3862\tlr: 0.000996\n","5, [12, 46] loss: 0.4430\tlr: 0.000996\n","5, [16, 46] loss: 0.2401\tlr: 0.000995\n","5, [20, 46] loss: 0.2088\tlr: 0.000995\n","5, [24, 46] loss: 0.2198\tlr: 0.000995\n","5, [28, 46] loss: 0.2743\tlr: 0.000995\n","5, [32, 46] loss: 0.2699\tlr: 0.000995\n","5, [36, 46] loss: 0.2240\tlr: 0.000994\n","5, [40, 46] loss: 0.1939\tlr: 0.000994\n","5, [44, 46] loss: 0.2418\tlr: 0.000994\n","Validation loss: 0.314258\n","Validation accuracy: 91.90 %\n","Epoch 5: Validation loss improved to 0.314258. Model saved.\n","6, [4, 46] loss: 0.2110\tlr: 0.000994\n","6, [8, 46] loss: 0.1891\tlr: 0.000993\n","6, [12, 46] loss: 0.2181\tlr: 0.000993\n","6, [16, 46] loss: 0.3792\tlr: 0.000993\n","6, [20, 46] loss: 0.1339\tlr: 0.000993\n","6, [24, 46] loss: 0.2394\tlr: 0.000993\n","6, [28, 46] loss: 0.4185\tlr: 0.000992\n","6, [32, 46] loss: 0.3557\tlr: 0.000992\n","6, [36, 46] loss: 0.3156\tlr: 0.000992\n","6, [40, 46] loss: 0.2509\tlr: 0.000992\n","6, [44, 46] loss: 0.1482\tlr: 0.000991\n","Validation loss: 0.608737\n","Validation accuracy: 84.76 %\n","Epoch 6: No improvement in validation loss (0.608737). Epochs without improvement: 1/6\n","7, [4, 46] loss: 0.2558\tlr: 0.000991\n","7, [8, 46] loss: 0.2135\tlr: 0.000991\n","7, [12, 46] loss: 0.1334\tlr: 0.000990\n","7, [16, 46] loss: 0.1893\tlr: 0.000990\n","7, [20, 46] loss: 0.3505\tlr: 0.000990\n","7, [24, 46] loss: 0.2432\tlr: 0.000990\n","7, [28, 46] loss: 0.2032\tlr: 0.000989\n","7, [32, 46] loss: 0.2195\tlr: 0.000989\n","7, [36, 46] loss: 0.3908\tlr: 0.000989\n","7, [40, 46] loss: 0.2102\tlr: 0.000989\n","7, [44, 46] loss: 0.2604\tlr: 0.000988\n","Validation loss: 0.971336\n","Validation accuracy: 78.33 %\n","Epoch 7: No improvement in validation loss (0.971336). Epochs without improvement: 2/6\n","8, [4, 46] loss: 0.3075\tlr: 0.000988\n","8, [8, 46] loss: 0.3465\tlr: 0.000987\n","8, [12, 46] loss: 0.2138\tlr: 0.000987\n","8, [16, 46] loss: 0.1718\tlr: 0.000987\n","8, [20, 46] loss: 0.2802\tlr: 0.000987\n","8, [24, 46] loss: 0.1673\tlr: 0.000986\n","8, [28, 46] loss: 0.1633\tlr: 0.000986\n","8, [32, 46] loss: 0.1410\tlr: 0.000986\n","8, [36, 46] loss: 0.1539\tlr: 0.000985\n","8, [40, 46] loss: 0.2112\tlr: 0.000985\n","8, [44, 46] loss: 0.1969\tlr: 0.000985\n","Validation loss: 0.650803\n","Validation accuracy: 86.67 %\n","Epoch 8: No improvement in validation loss (0.650803). Epochs without improvement: 3/6\n","9, [4, 46] loss: 0.1074\tlr: 0.000984\n","9, [8, 46] loss: 0.2522\tlr: 0.000984\n","9, [12, 46] loss: 0.2128\tlr: 0.000983\n","9, [16, 46] loss: 0.0439\tlr: 0.000983\n","9, [20, 46] loss: 0.3408\tlr: 0.000983\n","9, [24, 46] loss: 0.1671\tlr: 0.000982\n","9, [28, 46] loss: 0.2272\tlr: 0.000982\n","9, [32, 46] loss: 0.1597\tlr: 0.000982\n","9, [36, 46] loss: 0.1190\tlr: 0.000981\n","9, [40, 46] loss: 0.0464\tlr: 0.000981\n","9, [44, 46] loss: 0.3999\tlr: 0.000981\n","Validation loss: 0.972438\n","Validation accuracy: 77.86 %\n","Epoch 9: No improvement in validation loss (0.972438). Epochs without improvement: 4/6\n","10, [4, 46] loss: 0.1955\tlr: 0.000980\n","10, [8, 46] loss: 0.2147\tlr: 0.000980\n","10, [12, 46] loss: 0.1320\tlr: 0.000979\n","10, [16, 46] loss: 0.2169\tlr: 0.000979\n","10, [20, 46] loss: 0.1615\tlr: 0.000978\n","10, [24, 46] loss: 0.1238\tlr: 0.000978\n","10, [28, 46] loss: 0.0528\tlr: 0.000978\n","10, [32, 46] loss: 0.1067\tlr: 0.000977\n","10, [36, 46] loss: 0.1522\tlr: 0.000977\n","10, [40, 46] loss: 0.1556\tlr: 0.000976\n","10, [44, 46] loss: 0.1961\tlr: 0.000976\n","Validation loss: 0.224273\n","Validation accuracy: 95.00 %\n","Epoch 10: Validation loss improved to 0.224273. Model saved.\n","11, [4, 46] loss: 0.1296\tlr: 0.000975\n","11, [8, 46] loss: 0.3347\tlr: 0.000975\n","11, [12, 46] loss: 0.1485\tlr: 0.000975\n","11, [16, 46] loss: 0.1725\tlr: 0.000974\n","11, [20, 46] loss: 0.2483\tlr: 0.000974\n","11, [24, 46] loss: 0.3150\tlr: 0.000973\n","11, [28, 46] loss: 0.2169\tlr: 0.000973\n","11, [32, 46] loss: 0.2629\tlr: 0.000972\n","11, [36, 46] loss: 0.1538\tlr: 0.000972\n","11, [40, 46] loss: 0.1302\tlr: 0.000971\n","11, [44, 46] loss: 0.2216\tlr: 0.000971\n","Validation loss: 0.329416\n","Validation accuracy: 90.95 %\n","Epoch 11: No improvement in validation loss (0.329416). Epochs without improvement: 1/6\n","12, [4, 46] loss: 0.1383\tlr: 0.000970\n","12, [8, 46] loss: 0.1885\tlr: 0.000970\n","12, [12, 46] loss: 0.0327\tlr: 0.000969\n","12, [16, 46] loss: 0.0681\tlr: 0.000969\n","12, [20, 46] loss: 0.0532\tlr: 0.000968\n","12, [24, 46] loss: 0.1129\tlr: 0.000968\n","12, [28, 46] loss: 0.0648\tlr: 0.000967\n","12, [32, 46] loss: 0.2148\tlr: 0.000967\n","12, [36, 46] loss: 0.0283\tlr: 0.000966\n","12, [40, 46] loss: 0.1800\tlr: 0.000966\n","12, [44, 46] loss: 0.0862\tlr: 0.000965\n","Validation loss: 0.312071\n","Validation accuracy: 91.67 %\n","Epoch 12: No improvement in validation loss (0.312071). Epochs without improvement: 2/6\n","13, [4, 46] loss: 0.1267\tlr: 0.000965\n","13, [8, 46] loss: 0.0736\tlr: 0.000964\n","13, [12, 46] loss: 0.1120\tlr: 0.000964\n","13, [16, 46] loss: 0.0616\tlr: 0.000963\n","13, [20, 46] loss: 0.1697\tlr: 0.000963\n","13, [24, 46] loss: 0.1285\tlr: 0.000962\n","13, [28, 46] loss: 0.1127\tlr: 0.000962\n","13, [32, 46] loss: 0.2977\tlr: 0.000961\n","13, [36, 46] loss: 0.1557\tlr: 0.000961\n","13, [40, 46] loss: 0.2273\tlr: 0.000960\n","13, [44, 46] loss: 0.2753\tlr: 0.000960\n","Validation loss: 0.344487\n","Validation accuracy: 89.52 %\n","Epoch 13: No improvement in validation loss (0.344487). Epochs without improvement: 3/6\n","14, [4, 46] loss: 0.0385\tlr: 0.000959\n","14, [8, 46] loss: 0.1825\tlr: 0.000958\n","14, [12, 46] loss: 0.1598\tlr: 0.000958\n","14, [16, 46] loss: 0.1439\tlr: 0.000957\n","14, [20, 46] loss: 0.1353\tlr: 0.000957\n","14, [24, 46] loss: 0.0986\tlr: 0.000956\n","14, [28, 46] loss: 0.0828\tlr: 0.000955\n","14, [32, 46] loss: 0.0656\tlr: 0.000955\n","14, [36, 46] loss: 0.0953\tlr: 0.000954\n","14, [40, 46] loss: 0.2051\tlr: 0.000954\n","14, [44, 46] loss: 0.1150\tlr: 0.000953\n","Validation loss: 0.463436\n","Validation accuracy: 87.14 %\n","Epoch 14: No improvement in validation loss (0.463436). Epochs without improvement: 4/6\n","15, [4, 46] loss: 0.1467\tlr: 0.000952\n","15, [8, 46] loss: 0.0649\tlr: 0.000952\n","15, [12, 46] loss: 0.0618\tlr: 0.000951\n","15, [16, 46] loss: 0.0640\tlr: 0.000951\n","15, [20, 46] loss: 0.1429\tlr: 0.000950\n","15, [24, 46] loss: 0.0337\tlr: 0.000949\n","15, [28, 46] loss: 0.0595\tlr: 0.000949\n","15, [32, 46] loss: 0.0297\tlr: 0.000948\n","15, [36, 46] loss: 0.0685\tlr: 0.000948\n","15, [40, 46] loss: 0.1060\tlr: 0.000947\n","15, [44, 46] loss: 0.0840\tlr: 0.000946\n","Validation loss: 0.360852\n","Validation accuracy: 91.19 %\n","Epoch 15: No improvement in validation loss (0.360852). Epochs without improvement: 5/6\n","16, [4, 46] loss: 0.0403\tlr: 0.000945\n","16, [8, 46] loss: 0.0319\tlr: 0.000945\n","16, [12, 46] loss: 0.0937\tlr: 0.000944\n","16, [16, 46] loss: 0.0216\tlr: 0.000944\n","16, [20, 46] loss: 0.0534\tlr: 0.000943\n","16, [24, 46] loss: 0.0185\tlr: 0.000942\n","16, [28, 46] loss: 0.0410\tlr: 0.000942\n","16, [32, 46] loss: 0.1259\tlr: 0.000941\n","16, [36, 46] loss: 0.0493\tlr: 0.000940\n","16, [40, 46] loss: 0.0709\tlr: 0.000940\n","16, [44, 46] loss: 0.0696\tlr: 0.000939\n","Validation loss: 0.237404\n","Validation accuracy: 92.62 %\n","Epoch 16: No improvement in validation loss (0.237404). Epochs without improvement: 6/6\n","Early stopping triggered after 16 epochs. Best validation loss: 0.224273\n","Finished Training\n"]}]},{"cell_type":"code","source":["# Training and Validation section remains unchanged\n","\n","# Una volta terminato il training, carica il modello migliore salvato\n","print(\"Loading the best saved model...\")\n","net.load_state_dict(torch.load(\"net_best.pth\"))  # Carica il modello migliore salvato\n","net.to(device)  # Assicurati che il modello sia caricato sul dispositivo corretto (GPU o CPU)\n","\n","# Inizia la valutazione sul test set\n","print(\"Starting evaluation on the test set...\")\n","\n","# Passa il modello in modalità di valutazione (disattiva il dropout, batchnorm, ecc.)\n","net.eval()\n","\n","# Variabili per memorizzare le predizioni e i label del test set\n","test_preds = []\n","test_labels = []\n","test_correct = 0\n","test_total = 0\n","\n","# Nessuna necessità di calcolare i gradienti durante la fase di test\n","with torch.no_grad():\n","    for i, data in enumerate(test_loader):\n","        # Carica inputs e labels\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device).long()\n","\n","        # Esegui una forward pass\n","        outputs = net(inputs)\n","\n","        # Trova la classe con la probabilità più alta\n","        _, predicted = torch.max(outputs.cpu(), 1)\n","        test_preds.extend(predicted.cpu().numpy())\n","        test_labels.extend(labels.cpu().numpy())\n","\n","        # Aggiorna il conteggio dei totali\n","        test_total += labels.size(0)\n","        # Conta le predizioni corrette\n","        test_correct += (predicted == labels.cpu()).sum().item()\n","\n","# Calcola l'accuratezza sul test set\n","test_accuracy = 100 * test_correct / test_total\n","print(f\"Test accuracy: {test_accuracy:.2f} %\")\n","\n","# Optional: Se vuoi calcolare metriche aggiuntive (ad esempio precision, recall, f1-score)\n","from sklearn.metrics import classification_report\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(test_labels, test_preds))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aq1beCQbswCT","executionInfo":{"status":"ok","timestamp":1727529722195,"user_tz":-120,"elapsed":1556,"user":{"displayName":"Enrico Marta","userId":"06633031102520337170"}},"outputId":"e2582cd4-174c-49e5-92cd-6b9426874c5a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading the best saved model...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-12-bce58420c7fc>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  net.load_state_dict(torch.load(\"net_best.pth\"))  # Carica il modello migliore salvato\n"]},{"output_type":"stream","name":"stdout","text":["Starting evaluation on the test set...\n","Test accuracy: 92.89 %\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.91      1.00      0.95        10\n","           1       1.00      1.00      1.00        10\n","           2       0.75      0.90      0.82        10\n","           3       0.91      1.00      0.95        10\n","           4       0.91      1.00      0.95        10\n","           5       1.00      0.80      0.89        10\n","           6       1.00      1.00      1.00        11\n","           7       1.00      0.70      0.82        10\n","           8       0.90      0.90      0.90        10\n","           9       0.90      0.90      0.90        10\n","          10       0.91      1.00      0.95        10\n","          11       0.91      1.00      0.95        10\n","          12       1.00      0.80      0.89        10\n","          13       0.69      0.90      0.78        10\n","          14       1.00      1.00      1.00        10\n","          15       0.91      1.00      0.95        10\n","          16       1.00      1.00      1.00        10\n","          17       1.00      0.80      0.89        10\n","          18       1.00      1.00      1.00        10\n","          19       1.00      1.00      1.00        10\n","          20       1.00      0.80      0.89        10\n","\n","    accuracy                           0.93       211\n","   macro avg       0.94      0.93      0.93       211\n","weighted avg       0.94      0.93      0.93       211\n","\n"]}]}]}